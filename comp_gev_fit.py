"""
Compute the GEV fit
"""
import numpy as np
import gev_r
import matplotlib.pyplot as plt
import xarray
import codeLib
import commonLib
import scipy.stats

# import np.random

def boots(data, temp_values, rtn_periods, rng=None, nsamp=1000, dim='realization'):
    """
    Generate bootstrap samples.
    """
    if rng is None:
        rng = np.random.default_rng()
    npt = data.realization.size
    lst = []
    orig = np.arange(0, npt)
    for indx in range(0, nsamp):
        print("#", end='')
        indices = rng.integers(npt, size=npt)

        sample = comp_stats(data.isel({dim:indices}).assign_coords({dim:orig}), temp_values, rtn_periods,
                            dim=dim)
        sample = sample.expand_dims(sample=1).assign_coords(sample=[indx])
        lst.append(sample)
        # breakpoint()
        if (indx + 1) % 100 == 0:
            print(f" {indx + 1} ")
    result = xarray.concat(lst, dim='sample')
    print()
    return result


def comp_stats(data, temp_values, rtn_periods, dim='realization'):
    """
    Compute survival function, inverse survival fn for hist and nat fits. Also return hist and natural fits
    """
    fits = gev_r.xarray_gev_python(data, dim=dim, loc=20, scale=2)  # include guess for params.

    params = gev_r.param_at_cov(fits.Parameters, 0)
    sf = gev_r.xarray_sf(temp_values, params, output_dim_name=data.name)
    isf = gev_r.xarray_isf(1.0 / rtn_periods, params)
    result = xarray.merge([sf, isf, fits])
    return result


# noinspection PyShadowingNames
def prob_rat_uncert(data, quantile=None, method='percentile', pr_est=None, distribution=scipy.stats.lognorm):
    """
    Compute uncertainties in prob-ratios from bootstrapped data.

    :param data: samples of prob-ratios generated by bootstrapping. Dim 0 is over samples, Dim 1 over different PRs.
    :param quantile: the quantiles wanted for the uncertainty estimate. Default is [0.05, 0.95]
    :param method: method to compute the uncertainty -- one of:
     see Paciorek et al 2018 https://doi.org/10.1016/j.wace.2018.01.002
        'percentile' -- use bootstrap percentile interval
        'basic' -- use basic bootstrap interval
        'distribution' -- use a distribution fit.
    :param pr_est: estimate of probability ratio from non bootstrapped data. Used for 'basic' method
    :param distribution: distribution to use to fit the data if that option is selected. Default is scipy.stats.lognorm
    :return: uncertainties - a m x data.shape[1] array of quantiles  & the ks probability (None for everything but 'distribution' method.)
       where m is the number of quantiles requested.
    """
    if quantile is None:
        quantile = [0.05, 0.95]
    allowed_methods = {'percentile', 'basic', 'distribution'}
    if method not in allowed_methods:
        raise Exception(f"Method: {method} is not in ", allowed_methods)

    ks = None

    if method == 'percentile':
        uncerts = np.quantile(data, quantile, axis=0)  # % bootstrap %
    elif method == 'basic':
        uncerts = 2 * pr_est - np.quantile(data, quantile, axis=0)[::-1]
    elif method == 'distribution':
        p = distribution.fit(data)
        d = distribution(*p)
        uncerts=d.ppf(quantile)
        ks=scipy.stats.kstest(data, d.cdf).pvalue
        uncerts = np.array(uncerts)  # make it a numpy array
        ks = np.array(ks)  # ditto!
    else:
        raise Exception(f"Unknown method {method}")
    return uncerts, ks


temp_values = np.linspace(20, 40, 5000)
rtn_periods = np.geomspace(5, 1e4, 5000)
hist525 = dict()
nat525 = dict()
hist525_bs = dict()
nat525_bs = dict()
hist525_pool = dict()
nat525_pool = dict()
hist525_pool_bs = dict()
nat525_pool_bs = dict()
var_lookup = dict(tas='tas2Max', tasmax='tasmaxMax')
rng = np.random.default_rng()
nsamp = 1000  # set to 1000 for final calcs.
for var, running in zip(['tas','tasmax'], [2, None]):
    var_sel = var_lookup[var]
    # hist105_data = xarray.load_dataset(codeLib.output_dir / f'hist105_ens_{var}_roll{running}.nc')[var_sel]-273.15
    # nat105_data = xarray.load_dataset(codeLib.output_dir / f'nat105_ens_{var}_roll{running}.nc')[var_sel]-273.15

    hist525_data = xarray.load_dataset(codeLib.output_dir / f'hist525_ens_{var}_roll{running}.nc')[var_sel] - 273.15
    nat525_data = xarray.load_dataset(codeLib.output_dir / f'nat525_ens_{var}_roll{running}.nc')[var_sel] - 273.15



    hist525[var] = comp_stats(hist525_data, temp_values, rtn_periods)
    nat525[var] = comp_stats(nat525_data, temp_values, rtn_periods)

    hist525_bs[var] = boots(hist525_data,  temp_values, rtn_periods, rng=rng, nsamp=nsamp)
    nat525_bs[var] = boots(nat525_data,  temp_values, rtn_periods, rng=rng, nsamp=nsamp)
    # now compute the pooled values
    hist525_data_pool= hist525_data.stack(ensemble_time=['time','realization'])
    hist525_pool[var] = comp_stats(hist525_data_pool, temp_values, rtn_periods,dim='ensemble_time')
    hist525_pool_bs[var] = boots(hist525_data_pool,  temp_values, rtn_periods, rng=rng, nsamp=nsamp,dim='ensemble_time')
    
    nat525_data_pool=  nat525_data.stack(ensemble_time=['time','realization'])
    nat525_pool[var] = comp_stats( nat525_data_pool, temp_values, rtn_periods,dim='ensemble_time')
    nat525_pool_bs[var] = boots( nat525_data_pool,  temp_values, rtn_periods, rng=rng, nsamp=nsamp,dim='ensemble_time')

    #nat525_bs[var] = boots(nat525_data,  temp_values, rtn_periods, rng=rng, nsamp=nsamp)

## make some plots
fig, axes = plt.subplots(nrows=1, ncols=len(hist525.keys()), num='MO_attrib', figsize=[8, 6], clear=True, squeeze=False)
for ax, var, critValue in zip(axes.flatten(), hist525.keys(), [26.52, 35.39]):
    hist = hist525[var]
    nat = nat525[var]
    hist_bs = hist525_bs[var].quantile([0.05, 0.95], 'sample')
    nat_bs = nat525_bs[var].quantile([0.05, 0.95], 'sample')
    varl = var_lookup[var]

    for time, col in zip(hist.time, ['red', 'blue']):
        qhist = (1.0 / hist_bs.sf.sel(time=time))
        qnat = (1.0 / nat_bs.sf.sel(time=time))
        (1.0 / hist.sf.sel(time=time)).plot(ax=ax, label=f"hist{int(time.dt.year)}", y=varl, color=col, zorder=10)
        ax.fill_betweenx(qhist[varl], qhist.isel(quantile=0), qhist.isel(quantile=1), color=col, alpha=0.4, zorder=4)
        (1.0 / nat.sf.sel(time=time)).plot(ax=ax, label=f"nat{int(time.dt.year)}", y=varl, linestyle='dashed', color=col,
                                        zorder=10)
        # ax.fill_betweenx(qnat[varl],qnat.isel(quantile=0),qnat.isel(quantile=1),color=col,alpha=0.2,zorder=5)
    ax.set_xlim(1, 2000)
    ax.set_xlabel("Return Time (years)")
    ax.set_ylim(20, 40)
    ax.set_xscale('log')
    ax.legend()
    ax.set_title(var)
    # ax.axhline(critValue, color='black', linestyle='dashed')
    for v in [10, 100, 1000]:
        ax.axvline(v, color='black', linestyle='dashed')
fig.tight_layout()
fig.show()

## work out 1:100 & 1:1000 values for all years.
probs = dict(tas=1.0e-2, tasmax=1.0e-3)
colors = ['red', 'blue']
q = [0.05, 0.95]  # uncerts

fig, axes = plt.subplots(nrows=2, ncols=len(hist525.keys()), num='MO_attrib_fix_rp', figsize=[8, 6], clear=True,
                         squeeze=False)
for ax_delta, ax_pr,  var in zip(axes[0], axes[1], hist525.keys()):
    pv = [probs[var]]
    varl = var_lookup[var]
    values = hist525[var].isf.interp(probability=pv)  # values for pr.
    delta_t = hist525[var].isf.interp(probability=pv) - nat525[var].isf.interp(probability=pv)  # change in t.
    delta_t_bs = (hist525_bs[var].isf.interp(probability=pv) -
                  nat525_bs[var].isf.interp(probability=pv)).quantile(q,'sample')  # change in t.
    pr = hist525[var].sf.interp({varl: values}) / nat525[var].sf.interp({varl: values})
    values2 = hist525_bs[var].isf.interp(probability=pv)
    pr_bs = (hist525_bs[var].sf.interp({varl: values2}) / nat525_bs[var].sf.interp({varl: values2})).quantile(q, 'sample')

    # compute the pooled version.
    values_pool = hist525_pool[var].isf.interp(probability=pv)  # values for pr.
    delta_t_pool = hist525_pool[var].isf.interp(probability=pv) - nat525_pool[var].isf.interp(probability=pv)  # change in t.
    delta_t_pool_bs = (hist525_pool_bs[var].isf.interp(probability=pv) -
                  nat525_pool_bs[var].isf.interp(probability=pv)).quantile(q, 'sample')  # change in t.
    pr_pool = hist525_pool[var].sf.interp({varl: values_pool}) / nat525_pool[var].sf.interp({varl: values_pool})
    pr_pool_bs = (hist525_pool_bs[var].sf.interp({varl: values_pool}) / nat525_pool_bs[var].sf.interp({varl: values_pool}))#.quantile(q,'sample')

    for p, col in zip(pv, colors):
        ax_delta.plot(delta_t.time.dt.year, delta_t.sel(probability=p), marker='o', color=col,
                      label=f'rp:{int(1.0 / p):d}')
        dt = delta_t_bs.sel(probability=p)
        ax_delta.fill_between(dt.time.dt.year, dt.isel(quantile=0), dt.isel(quantile=1), alpha=0.2, color=col)
        ax_delta.axhline(delta_t.sel(probability=p).mean('time'), linestyle='dotted', color=col)
        ax_pr.plot(pr.time.dt.year, pr.sel(probability=p), marker='o', color=col)
        dp = pr_bs.sel(probability=p)
        dp = dp.where(np.isfinite(dp), np.nan)
        ax_pr.fill_between(dp.time.dt.year, dp.isel(quantile=0), dp.isel(quantile=1), alpha=0.2, color=col)
        ax_pr.axhline(np.exp(np.log(pr.sel(probability=p)).mean('time')), linestyle='dotted', color=col)
        print(f"Pooled  {var} Crit: {float(values_pool):3.1f} delta_t {float(delta_t_pool.sel(probability=p)):3.1f}",end=' ')
        # uncert next
        qv=prob_rat_uncert(delta_t_pool_bs.sel(probability=p).data, method='percentile')[0]
        print("(","-".join([f"{float(qq):3.1f}" for qq in qv]),end=") ")
        print(f"pr: {float(pr_pool.sel(probability=p)):3.1f}",end=' ') # pr values
        # uncert next
        qv=prob_rat_uncert(pr_pool_bs.sel(probability=p).data, method='percentile')[0]
        print("(","-".join([f"{float(qq):3.1f}" for qq in qv]),end=") ")
        print("")




    ax_delta.set_title(varl)
    ax_delta.set_ylabel(r"$\Delta$ T")
    ax_delta.axhline(0.0, color='black', linestyle='dashed')

    ax_pr.set_title(varl)
    ax_pr.set_ylabel(r"PR")
    ax_pr.set_yscale('log')
    ax_pr.set_ylim(0.1, 1e4)
    ax_pr.axhline(1.0, color='black', linestyle='dashed')
axes[0][0].legend()
fig.tight_layout()
fig.show()
commonLib.saveFig(fig)
